# Automated speech Recognition and sentiment Analysis

Automatic Speech Recognition (ASR) applications have increased greatly during the last decade due to the 
emergence of new devices and home automation hardware that can benefit greatly from allowing users 
to interact hands free, such as smart watches, earbuds, portable translators, and home assistants.

## The project consist of two distinct parts:

* Setting up an ASR model, ASR Stands for Automated Speech Recognition
* Perform the sentiment Analysis on the transcription generated by the aforementioned model


#### Part 1: Setting Up the ASR Model

We chose a model from Hugging face Hub that's fine-tuned for French ASR, **facebook/wav2vec2-large-xlsr-53-french** and 
**antoiloui/wav2vec2-large-xlsr-french** have been chosen. Whisper-Large-V3-French is fine-tuned on openai/whisper-large-v3 
to further enhance its performance on the French language and  We installed the necessary libraries, load the model, 
process the audio to make inference by passing the processed audio files through the ASR model.

Both model easily used with the ðŸ¤— Hugging Face pipeline class for audio transcription.
**Notice:** For long-form transcription (> 30 seconds), you can activate the process by passing the chunk_length_s argument. 
This approach segments the audio into smaller segments, processes them in parallel

 - Model Performance: We tested both models on the same datasets to assessing its accuracy, generalizability, 
 and robustness

#### Part 2: Sentiment Analysis

We built BERT model for sentiment Analysis using NLP approach, trained on 
[Allocine-french-movie-reviews](www.kaggle.com/datasets/djilax/allocine-french) dataset 
Transcribe the provided audio recording using ASR model, after we perform sentiment Analysis 
 - Model Performance: We tested both models on the same datasets to assessing its accuracy, generalizability, 
 and robustness.
 
#### Part 3: Make the Inference
 
 1. Pre-process the text: unction you've provided is used to tokenize a given text using the specified tokenizer,
 ensuring the text is padded or truncated to a specified maximum length, and the output is returned as PyTorch tensors
 
 2. Load the model: The function is made to load a trained model from a file, move it to the appropriate device (either GPU or CPU),
 and set it to evaluation mode
 
 3. The prediction: 
 Using the Bert directional model just trained, the function makes predictions of the transcription generated by ASR 
 model. It takes a text input, tokenizes it, and then passes it through the model
 to get a prediction, which is then mapped to either  ðŸ¤— positive or  :unamused: negative
 
  - Model Performance: We tested both models on the same datasets to assessing its accuracy, generalizability, 
 and robustness
 
 
 
 
 
 
 
 
 
 